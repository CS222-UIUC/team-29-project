# CODEBASE STRUCTURE

# Repository: ThreadFlow
./
├── .github/
│   └── workflows/
│       ├── docker-image.yml
│       ├── node.js.yml
│       └── python-app.yml
├── backend/
│   ├── Dockerfile
│   ├── app/
│   │   ├── __init__.py
│   │   ├── config.py
│   │   ├── main.py
│   │   ├── models.py
│   │   └── test_api.py
│   └── pyproject.toml
├── cloudbuild.yaml
├── docker-compose.yml
└── frontend/
    ├── Dockerfile
    ├── ensure-env.js
    ├── next.config.ts
    ├── package.json
    ├── run_tests.sh
    ├── src/
    │   ├── __tests__/
    │   │   ├── Auth.test.tsx
    │   │   ├── Chat.test.tsx
    │   │   ├── ErrorHandlingTest.tsx
    │   │   ├── ModelSelection.test.tsx
    │   │   └── modelUtils.test.ts
    │   ├── app/
    │   │   ├── ClientProviders.tsx
    │   │   ├── about/
    │   │   │   └── page.tsx
    │   │   ├── api/
    │   │   │   └── auth/
    │   │   │       └── [...nextauth]/
    │   │   │           └── route.ts
    │   │   ├── auth/
    │   │   │   ├── error/
    │   │   │   │   └── page.tsx
    │   │   │   └── signin/
    │   │   │       └── page.tsx
    │   │   ├── chat/
    │   │   │   └── page.tsx
    │   │   ├── globals.css
    │   │   ├── layout.tsx
    │   │   └── page.tsx
    │   ├── types/
    │   │   ├── models.ts
    │   │   └── next-auth.d.ts
    │   └── utils/
    │       └── modelUtils.ts
    └── tsconfig.json

19 directories, 35 files



# FILE CONTENTS



--- File: .github/workflows/docker-image.yml ---

name: Docker Image CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:

  build:

    runs-on: ubuntu-latest
    
    env:
      NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
      GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
      GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

    steps:
    - uses: actions/checkout@v4
    
    - name: Build the backend Docker image
      run: docker build ./backend --file backend/Dockerfile --tag threadflow-backend:$(date +%s)
    
    - name: Build the frontend Docker image
      run: docker build ./frontend --file frontend/Dockerfile --target production --tag threadflow-frontend:$(date +%s)


--- File: .github/workflows/node.js.yml ---

# This workflow will do a clean installation of node dependencies, cache/restore them, build the source code and run tests across different versions of node
# For more information see: https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-nodejs

name: Frontend CI

on:
  push:
    branches: [ "main" ]
    paths:
      - 'frontend/**'  # Only run when frontend files change
  pull_request:
    branches: [ "main" ]
    paths:
      - 'frontend/**'

jobs:
  build:
    runs-on: ubuntu-latest
    
    defaults:
      run:
        working-directory: ./frontend
    
    env:
      NEXTAUTH_SECRET: ${{ secrets.NEXTAUTH_SECRET }}
      GOOGLE_CLIENT_ID: ${{ secrets.GOOGLE_CLIENT_ID }}
      GOOGLE_CLIENT_SECRET: ${{ secrets.GOOGLE_CLIENT_SECRET }}
      NEXTAUTH_URL: http://localhost:3000
    
    strategy:
      matrix:
        node-version: [20.x]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Use Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: './frontend/package-lock.json'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Lint
      run: npm run lint --if-present
    
    - name: Build
      run: npm run build --if-present
    
    - name: Test
      run: npm test --if-present


--- File: .github/workflows/python-app.yml ---

name: Python application

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libffi-dev
    
    - name: Install and configure Poetry
      uses: snok/install-poetry@v1
      with:
        version: 1.7.1
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Install dependencies
      working-directory: ./backend
      run: poetry install --no-interaction
    
    - name: Check code formatting with Black
      working-directory: ./backend
      run: poetry run black --check .
    
    - name: Check import sorting with isort
      working-directory: ./backend
      run: poetry run isort --check .
    
    - name: Lint with flake8
      working-directory: ./backend
      run: |
        poetry run flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics --exclude=.venv,build,dist
        poetry run flake8 . --count --exit-zero --max-complexity=10 --max-line-length=150 --statistics --exclude=.venv,build,dist
    
    - name: Lint with pylint
      working-directory: ./backend
      run: |
        poetry run pylint $(git ls-files '*.py')
    
    - name: Test with pytest
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      working-directory: ./backend
      run: poetry run pytest

--- File: backend/.env.example ---

# Database
MONGODB_URI=mongodb://mongo:27017/threadflow

# Model API Keys
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# JWT for authentication (future use)
JWT_SECRET=your_jwt_secret_here

--- File: backend/Dockerfile ---

FROM python:3.10-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Install Poetry
RUN pip install --no-cache-dir poetry --upgrade

# Copy poetry configuration
COPY pyproject.toml ./

# Configure poetry to not use a virtual environment
RUN poetry config virtualenvs.create false

# Generate a fresh lock file and install dependencies
RUN poetry lock && poetry install --no-interaction --no-ansi --no-root -vvv

# Copy project files
COPY . .

# Run the application
CMD uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

--- File: backend/app/__init__.py ---



--- File: backend/app/config.py ---

"""Configuration module for handling secrets and model configurations."""

import os
from typing import Dict, List

from google.cloud import secretmanager  # pylint: disable=E0611


def get_secret(secret_id, default_value=""):
    """Get a secret from Secret Manager or use default/env value"""
    # Check if we're running on Cloud Run
    if os.environ.get("K_SERVICE"):
        try:
            project_id = os.environ.get("GOOGLE_CLOUD_PROJECT", "threadflow-app")
            client = secretmanager.SecretManagerServiceClient()
            name = f"projects/{project_id}/secrets/{secret_id}/versions/latest"
            response = client.access_secret_version(request={"name": name})
            return response.payload.data.decode("UTF-8")
        except Exception as excp_err:  # pylint: disable=W0703
            print(f"Error accessing secret {secret_id}: {excp_err}")
            # Fall back to environment variable
            return os.environ.get(secret_id.replace("-", "_").upper(), default_value)
    else:
        # In development, use environment variables
        return os.environ.get(secret_id.replace("-", "_").upper(), default_value)


# Application settings
MONGODB_URI = get_secret("mongodb-uri", "mongodb://mongo:27017/threadflow")
JWT_SECRET = get_secret("jwt-secret", "dev_secret_key")

# API keys for different model providers
GEMINI_API_KEY = get_secret("gemini-api-key", "")
OPENAI_API_KEY = get_secret("openai-api-key", "")
ANTHROPIC_API_KEY = get_secret("anthropic-api-key", "")

# Model configurations
MODEL_CONFIGS: Dict[str, List[Dict[str, str]]] = {
    "google": [
        {
            "id": "gemini-2.5-pro-exp-03-25",
            "name": "Gemini 2.5 Pro Experimental",
            "description": "Latest experimental Gemini model with advanced capabilities",
        },
        {"id": "gemini-2.0-flash", "name": "Gemini 2.0 Flash", "description": "Fast, efficient model with strong performance"},
        {"id": "gemini-2.0-flash-lite", "name": "Gemini 2.0 Flash Lite", "description": "Lightweight model: fast & efficient"},
        {"id": "gemini-1.5-pro", "name": "Gemini 1.5 Pro", "description": "Reliable model for complex tasks"},
    ],
    "anthropic": [
        {"id": "claude-3-7-sonnet-20250219", "name": "Claude 3.7 Sonnet", "description": "Latest & most capable Sonnet"},
        {"id": "claude-3-5-sonnet-20241022", "name": "Claude 3.5 Sonnet v2", "description": "Balanced perf & cost Sonnet"},
        {"id": "claude-3-5-haiku-20241022", "name": "Claude 3.5 Haiku", "description": "Fast, efficient responses w/ Haiku"},
    ],
    "openai": [
        {"id": "gpt-4o", "name": "GPT-4o", "description": "OpenAI's latest multimodal model with optimal performance"},
    ],
}

# Default model to use if none specified
DEFAULT_MODEL_PROVIDER = "google"
DEFAULT_MODEL_ID = "gemini-2.5-pro-exp-03-25"


--- File: backend/app/main.py ---

"""
This module provides utility for the backend
This encases the main function for the backend
"""

import uuid
from datetime import datetime
from typing import List, Optional

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, EmailStr, Field

from app.config import DEFAULT_MODEL_ID, DEFAULT_MODEL_PROVIDER
from app.models import (
    Conversation, 
    User, 
    conversations_collection, 
    generate_response, 
    get_available_models, 
    users_collection,
    MessageItem
)

# Load environment variables
load_dotenv()

app = FastAPI(title="ThreadFlow API")

# Enable CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatMessage(BaseModel):
    """
    This class provides utility for the chatbot message
    Input: BaseModel - AI model to be used for the interface
    """

    message: str
    provider: str = DEFAULT_MODEL_PROVIDER
    model_id: str = DEFAULT_MODEL_ID
    user_id: Optional[str] = None
    conversation_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    conversation_id: str
    user_message_id: str
    assistant_message_id: str
    
class UserCreate(BaseModel):
    """User creation model for API requests"""
    id: str
    email: Optional[EmailStr] = None
    name: Optional[str] = None
    image: Optional[str] = None


class ConversationCreate(BaseModel):
    """Conversation creation model"""
    user_id: str
    title: str
    initial_message: Optional[str] = None

class ConversationMetadata(BaseModel):
    id: str
    user_id: str
    title: str
    created_at: datetime
    updated_at: datetime
    parent_conversation_id: Optional[str] = None
    branch_point_message_id: Optional[str] = None

class BranchRequest(BaseModel):
    message_id: str
    user_id: str
    
@app.get("/")
async def root():
    """Returns a message referencing the API"""
    return {"message": "Welcome to ThreadFlow API"}


@app.get("/health")
async def health_check():
    """Returns a message referencing the health of the API"""
    return {"status": "healthy"}


@app.get("/models")
async def models():
    """Returns available models and their configurations"""
    return get_available_models()


@app.post("/chat", response_model=ChatResponse)
async def chat(message: ChatMessage):
    """Asynchronous method for the chat interface"""
    if not message.user_id:
         # Allow anonymous chats for now, but they won't be saved persistently
         # Or raise HTTPException(status_code=400, detail="user_id is required to save conversation")
        try:
            response_text = await generate_response(
                message=message.message, provider=message.provider, model_id=message.model_id
            )
            # For anonymous chat, we can't provide real IDs back
            return ChatResponse(
                response=response_text,
                conversation_id="anonymous",
                user_message_id="anonymous",
                assistant_message_id="anonymous"
            )
        except HTTPException as excp_err:
            print(f"Error calling AI API (anonymous): {str(excp_err)}")
            # Return a simple dict for anonymous errors, or adjust ChatResponse
            raise HTTPException(status_code=excp_err.status_code, detail=str(excp_err.detail))
        except Exception as e:
            print(f"Unexpected error (anonymous): {e}")
            raise HTTPException(status_code=500, detail="An internal error occurred during anonymous chat.")
    conversation = None
    target_conversation_id = message.conversation_id
    if target_conversation_id:
        conversation_doc = await conversations_collection.find_one({"id": target_conversation_id, "user_id": message.user_id})
        if conversation_doc:
            # Load existing conversation
            conversation = Conversation(**conversation_doc)
            target_conversation_id = conversation.id # Ensure we use the validated ID
        else:
            # If conversation_id provided but not found/owned, treat as starting new
            target_conversation_id = None
    
    if not conversation:
        new_conv_id = str(uuid.uuid4())
        conversation = Conversation(
            id=new_conv_id,
            user_id=message.user_id,
            title=message.message[:30] + "..." if len(message.message) > 30 else message.message,
            messages=[],
            created_at=datetime.now(),
            updated_at=datetime.now()
        )
        target_conversation_id = new_conv_id
    
    user_message_id, assistant_message_id = str(uuid.uuid4()), str(uuid.uuid4())
    user_message_item = MessageItem(
        role="user",
        content=message.message,
        timestamp=datetime.now(),
        id=user_message_id
    )
    
    try:
        # Generate response using the specified provider and model
        response_text = await generate_response(message=message.message, provider=message.provider, model_id=message.model_id)
        
    except HTTPException as excp_err:
        # Log the error
        print(f"Error calling AI API: {str(excp_err)}")
        # Return a user-friendly error message
        return {"response": f"Sorry, I encountered an error when you requested: {str(excp_err)}"}
    except Exception as e:
        # Log the error
        print(f"Unexpected error: {e}")
        # Return a user-friendly error message
        return {"response": "Sorry, I encountered an unexpected error. Developer Team has been informed."}
    
    assistant_message_item = MessageItem(
        role="assistant",
        content=response_text,
        timestamp=datetime.now(),
        id=assistant_message_id
    )
    
    conversation.messages.append(user_message_item)
    conversation.messages.append(assistant_message_item)
    conversation.updated_at = datetime.now()
    await conversations_collection.replace_one(
        {"id": conversation.id},
        conversation.model_dump(mode="json"),
        upsert=True
    )

    return ChatResponse(
        response=response_text,
        conversation_id=conversation.id,
        user_message_id=user_message_id,
        assistant_message_id=assistant_message_id
    )

@app.post("/users", response_model=User)
async def create_user(user: UserCreate):
    """Create a new user or update if exists"""
    # Check if user exists
    existing = await users_collection.find_one({"id": user.id})
    user_data = user.model_dump() # Use model_dump for Pydantic v2+
    now = datetime.now()
    if existing:
        user_data["updated_at"] = now
        await users_collection.update_one({"id": user.id}, {"$set": user_data})
    else:
        user_data["created_at"] = now
        user_data["updated_at"] = now
        await users_collection.insert_one(user_data)
    result = await users_collection.find_one({"id": user.id})
    if not result:
         raise HTTPException(status_code=404, detail="User upsert failed") # Should not happen
    # Need to handle potential _id field if it exists and isn't part of the Pydantic model
    result.pop('_id', None)
    return User(**result)


@app.get("/users/{user_id}", response_model=User)
async def get_user(user_id: str):
    """Get user by ID"""
    user = await users_collection.find_one({"id": user_id})
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    user.pop('_id', None)
    return User(**user)


@app.get("/conversations", response_model=List[ConversationMetadata])
async def get_user_conversations_metadata(user_id: str):
    """
    Get metadata (excluding messages) for all conversations owned by a user,
    sorted by last updated time.
    """
    # get user_id from an authenticated  token - future

    # Check if user exists (optional, but good practice)
    user_exists = await users_collection.count_documents({"id": user_id})
    if not user_exists:
        # revealing 404 user not found maybe is giving security info
        return []

    # Define the projection to exclude messages
    projection = {"messages": 0, "_id": 0} # Exclude MongoDB default _id too

    conversations_cursor = conversations_collection.find(
        {"user_id": user_id},
        projection=projection
    ).sort("updated_at", -1)

    conversations_metadata = await conversations_cursor.to_list(length=None)

    # Pydantic validation before returning
    return [ConversationMetadata(**conv) for conv in conversations_metadata]

@app.get("/conversations/{conversation_id}", response_model=Conversation)
async def get_full_conversation(conversation_id: str, user_id: str): # Pass user_id for ownership check
     """
     Get the full content (including messages) for a specific conversation,
     checking for user ownership.
     """
     # Again, user_id should ideally come from auth token
     conversation_doc = await conversations_collection.find_one({"id": conversation_id})

     if not conversation_doc:
         raise HTTPException(status_code=404, detail="Conversation not found")

     # --- Ownership Check ---
     if conversation_doc.get("user_id") != user_id:
          raise HTTPException(status_code=403, detail="User does not have permission to access this conversation")
          # Or return 404 for obscurity
     conversation_doc.pop('_id', None)

     return Conversation(**conversation_doc)

@app.post("/conversations/{conversation_id}/branch", response_model=Conversation, status_code=201)
async def branch_conversation(conversation_id: str, branch_request: BranchRequest):
    """
    Creates a new conversation branch from a specific message in the parent conversation.
    """
    # Again, user_id ideally from auth context
    parent_user_id = branch_request.user_id

    # 1. Fetch Parent Conversation (Full Document)
    parent_doc = await conversations_collection.find_one({"id": conversation_id})
    if not parent_doc:
        raise HTTPException(status_code=404, detail="Parent conversation not found")

    # 2. Check Ownership
    if parent_doc.get("user_id") != parent_user_id:
        raise HTTPException(status_code=403, detail="User does not have permission to branch this conversation")

    parent_conversation = Conversation(**parent_doc) # Validate parent data

    # 3. Find Branch Point Message Index
    branch_message_id = branch_request.message_id
    branch_index = -1
    for i, msg in enumerate(parent_conversation.messages):
        if msg.id == branch_message_id:
            branch_index = i
            break

    if branch_index == -1:
        raise HTTPException(status_code=404, detail=f"Message ID '{branch_message_id}' not found in parent conversation '{conversation_id}'")

    # 4. Create New Branch Conversation Data
    new_branch_id = str(uuid.uuid4())
    
    # Copy messages up to and including the branch point message
    branch_messages = parent_conversation.messages[:branch_index + 1]

    branch_title = f"Branch from '{parent_conversation.title[:20]}...' @ msg {branch_index + 1}" # Example title

    new_branch_conversation = Conversation(
        id=new_branch_id,
        user_id=parent_user_id, # Branch owned by the same user
        title=branch_title,
        messages=branch_messages,
        created_at=datetime.now(),
        updated_at=datetime.now(), # Same as created_at initially
        parent_conversation_id=conversation_id, # Link to parent
        branch_point_message_id=branch_message_id # Link to specific message
    )

    # 5. Insert New Branch into DB
    await conversations_collection.insert_one(new_branch_conversation.model_dump(mode='json'))

    # 6. Return the full new branch conversation object
    return new_branch_conversation

@app.get("/debug/all-conversations")
async def get_all_conversations():
    """Debug endpoint: Get all conversations in the database"""
    conversations = await conversations_collection.find().to_list(length=100)
    # Convert MongoDB ObjectId to string to make it JSON serializable
    for conv in conversations:
        if "_id" in conv:
            conv["_id"] = str(conv["_id"])
    return conversations


@app.get("/debug/all-users")
async def get_all_users():
    """Debug endpoint: Get all users in the database"""
    users = await users_collection.find().to_list(length=100)
    # Convert MongoDB ObjectId to string to make it JSON serializable
    for user in users:
        if "_id" in user:
            user["_id"] = str(user["_id"])
    return users



--- File: backend/app/models.py ---

"""
Models module for handling interactions with different AI services
"""

import asyncio
from datetime import datetime
from typing import Dict, List, Optional
import uuid
import anthropic
import google.generativeai as genai
import motor.motor_asyncio
import openai
from fastapi import HTTPException
from pydantic import BaseModel, Field

from app.config import ANTHROPIC_API_KEY, DEFAULT_MODEL_ID, DEFAULT_MODEL_PROVIDER, GEMINI_API_KEY, MODEL_CONFIGS, MONGODB_URI, OPENAI_API_KEY  # noqa: E501

# Configure API clients
genai.configure(api_key=GEMINI_API_KEY)

# MongoDB client
client = motor.motor_asyncio.AsyncIOMotorClient(MONGODB_URI)
db = client.threadflow
users_collection = db.users
conversations_collection = db.conversations

# Model provider clients
_ANTHROPIC_CLIENT = None
_OPENAI_CLIENT = None

# Message format within conversation.messages (for reference)
# {
#    "id": str,  # Unique UUID for the message
#    "role": str,  # "user" or "assistant"
#    "content": str,  # Message content
#    "timestamp": datetime  # When the message was created
# }

class MessageItem(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    role: str
    content: str
    timestamp: datetime = Field(default_factory=datetime.now)
    
# User models
class User(BaseModel):
    """User model for storing user information"""
    id: str
    name: Optional[str] = None
    email: Optional[str] = None
    image: Optional[str] = None
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    
class Conversation(BaseModel):
    """Conversation model for storing chat history"""
    id: str
    user_id: str
    title: str
    messages: List[MessageItem] = []
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)
    parent_conversation_id: Optional[str] = None
    branch_point_message_id: Optional[str] = None




def get_anthropic_client():
    """Get or create Anthropic client"""
    global _ANTHROPIC_CLIENT  # pylint: disable=W0603
    if _ANTHROPIC_CLIENT is None and ANTHROPIC_API_KEY:
        _ANTHROPIC_CLIENT = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    return _ANTHROPIC_CLIENT


def get_openai_client():
    """Get or create OpenAI client"""
    global _OPENAI_CLIENT  # pylint: disable=W0603
    if _OPENAI_CLIENT is None and OPENAI_API_KEY:
        _OPENAI_CLIENT = openai.OpenAI(api_key=OPENAI_API_KEY)
    return _OPENAI_CLIENT


async def generate_response(message: str, provider: str = DEFAULT_MODEL_PROVIDER, model_id: str = DEFAULT_MODEL_ID) -> str:
    """Generate a response using the specified model provider and model ID"""
    try:
        # Map of providers to their API keys
        provider_keys = {"google": GEMINI_API_KEY, "anthropic": ANTHROPIC_API_KEY, "openai": OPENAI_API_KEY}

        # Map of providers to their generator functions
        provider_functions = {"google": _gen_w_gemini, "anthropic": _gen_w_anthropic, "openai": _gen_w_openai}

        # Validate provider exists
        if provider not in MODEL_CONFIGS:
            raise HTTPException(status_code=400, detail=f"Invalid provider: {provider}")

        # Validate model exists for provider
        valid_models = [model["id"] for model in MODEL_CONFIGS[provider]]
        if model_id not in valid_models:
            raise HTTPException(status_code=400, detail=f"Invalid model ID for provider {provider}: {model_id}")

        # Check if any API keys are configured
        if not any(provider_keys.values()):
            return "No API key found. Set 1 API key in your environment variables or .env file."

        # Check if this provider's API key is configured
        if not provider_keys.get(provider):
            return f"{provider.capitalize()} API key not found. Set {provider.upper()}_API_KEY."

        # Generate the response
        return await provider_functions[provider](message, model_id)

    except Exception as e:  # pylint: disable=W0703, C0103
        raise HTTPException(status_code=500, detail=f"Error generating response: {str(e)}")  # pylint: disable=W0707


async def _gen_w_gemini(message: str, model_id: str) -> str:
    """Generate a response using Google's Gemini models"""
    try:
        if not GEMINI_API_KEY:
            return "Gemini API key not found. Set GEMINI_API_KEY in your environment variables."

        # Create model instance
        model = genai.GenerativeModel(model_id)

        # Run in executor to prevent blocking
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(None, lambda: model.generate_content(message))

        return response.text
    except Exception as e:  # pylint: disable=W0703, C0103
        raise HTTPException(status_code=500, detail=f"Error with Gemini API: {str(e)}")  # pylint: disable=W0707


async def _gen_w_anthropic(message: str, model_id: str) -> str:
    """Generate a response using Anthropic's Claude models"""
    try:
        client = get_anthropic_client()
        if not client:
            return "Anthropic API key not found. Set ANTHROPIC_API_KEY in your env variables"

        # Run in executor to prevent blocking
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None, lambda: client.messages.create(model=model_id, max_tokens=1024, messages=[{"role": "user", "content": message}])  # noqa: E501
        )

        return response.content[0].text
    except Exception as e:  # pylint: disable=W0703, C0103
        raise HTTPException(status_code=500, detail=f"Error with Anthropic API: {str(e)}")  # pylint: disable=W0707


async def _gen_w_openai(message: str, model_id: str) -> str:
    """Generate a response using OpenAI's GPT models"""
    try:
        client = get_openai_client()
        if not client:
            return "OpenAI API key not found. Set OPENAI_API_KEY in your environment variables."

        # Run in executor to prevent blocking
        loop = asyncio.get_event_loop()
        response = await loop.run_in_executor(
            None,
            lambda: client.chat.completions.create(model=model_id, messages=[{"role": "user", "content": message}], max_tokens=1024),  # noqa: E501
        )

        return response.choices[0].message.content
    except Exception as e:  # pylint: disable=W0703, C0103
        raise HTTPException(status_code=500, detail=f"Error with OpenAI API: {str(e)}")  # pylint: disable=W0707


def get_available_models() -> Dict:
    """Get all available models with their configuration and availability status"""
    available_models = {
        "google": {"available": bool(GEMINI_API_KEY), "models": MODEL_CONFIGS["google"]},
        "anthropic": {"available": bool(ANTHROPIC_API_KEY), "models": MODEL_CONFIGS["anthropic"]},
        "openai": {"available": bool(OPENAI_API_KEY), "models": MODEL_CONFIGS["openai"]},
    }

    return available_models


--- File: backend/app/test_api.py ---

"""
This module provides testing utility for the backend
Functions:
- test_root_status(): Test API status
- test_health(): Test API health
- test_chat_basic(): Baseline test for chatbot
- test_models_endpoint(): Test models listing endpoint
- test_chat_with_model_params(): Test chat with model parameters
"""

from fastapi.testclient import TestClient

from app.main import app

client = TestClient(app)


def test_root_status():
    """Test API status"""
    response = client.get("/")
    assert response.status_code == 200
    assert response.json() == {"message": "Welcome to ThreadFlow API"}


def test_health():
    """Test health"""
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json() == {"status": "healthy"}


def test_chat_basic():
    """Baseline test for chatbot"""
    response = client.post("/chat", json={"message": "Hi!"})
    assert response.status_code == 200
    assert "response" in response.json()


def test_models_endpoint():
    """Test models listing endpoint"""
    response = client.get("/models")
    assert response.status_code == 200
    data = response.json()

    # Check that the response contains the expected provider keys
    assert "google" in data
    assert "anthropic" in data
    assert "openai" in data

    # Check that each provider has the expected structure
    for provider in ["google", "anthropic", "openai"]:
        assert "available" in data[provider]
        assert "models" in data[provider]
        assert isinstance(data[provider]["models"], list)

        # Check model structure for non-empty model lists
        if data[provider]["models"]:
            model = data[provider]["models"][0]
            assert "id" in model
            assert "name" in model
            assert "description" in model


def test_chat_with_model_params():
    """Test chat with model parameters"""
    response = client.post("/chat", json={"message": "Hi!", "provider": "google", "model_id": "gemini-1.5-pro"})
    assert response.status_code == 200
    assert "response" in response.json()


--- File: backend/pyproject.toml ---

[tool.poetry]
name = "threadflow-backend"
version = "0.1.0"
description = "Backend for ThreadFlow chat application"
authors = ["Thread <tthreadflow@gmail.com>"]
packages = [
    {include = "app"}
]

[tool.poetry.dependencies]
python = ">=3.10,<3.11"
fastapi = "*"
uvicorn = "*"
motor = "*"
pydantic = "*"
python-jose = "*"
google-cloud-secret-manager = "*"
google-generativeai = "*"
python-dotenv = "*"
anthropic = "*"
openai = "*"
email-validator = "*"
pydantic-extra-types = "*"

[tool.poetry.group.dev.dependencies]
pytest = "*"
black = "*"
isort = "*"
flake8 = "*"
pylint = "*"
httpx = "*"

[tool.black]
line-length = 150
target-version = ["py310"]
include = '\.pyi?$'

[tool.isort]
profile = "black"
line_length = 150

[tool.pylint.messages_control]
disable = [
    "too-few-public-methods",
    "missing-module-docstring",
    "missing-function-docstring",
    "broad-exception-caught"
]

[tool.pylint.format]
max-line-length = "150"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

--- File: cloudbuild.yaml ---

steps:
  # Build backend image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/backend:${SHORT_SHA}', './backend']
    id: 'build-backend'

  # Push backend image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/backend:${SHORT_SHA}']
    id: 'push-backend'

  # Build frontend image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-t', 'us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/frontend:${SHORT_SHA}', '--target', 'production', './frontend']
    id: 'build-frontend'

  # Push frontend image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', 'us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/frontend:${SHORT_SHA}']
    id: 'push-frontend'

  # Create a file with deployment status
  - name: 'gcr.io/cloud-builders/gcloud'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        echo "Images built and pushed to Artifact Registry:"
        echo "Backend: us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/backend:${SHORT_SHA}"
        echo "Frontend: us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/frontend:${SHORT_SHA}"
        echo ""
        echo "Ready for deployment. To deploy, run:"
        echo "gcloud run deploy threadflow-backend --image=us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/backend:${SHORT_SHA} --region=us-central1"
        echo "gcloud run deploy threadflow-frontend --image=us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/frontend:${SHORT_SHA} --region=us-central1"

images:
  - 'us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/backend:${SHORT_SHA}'
  - 'us-central1-docker.pkg.dev/${PROJECT_ID}/threadflow-repo/frontend:${SHORT_SHA}'

timeout: '1200s'

--- File: docker-compose.yml ---

services:
  # Backend service with updated environment variables
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
      - /app/node_modules
    environment:
      - MONGODB_URI=mongodb://mongo:27017/threadflow
      # Model provider API keys
      - GEMINI_API_KEY=${GEMINI_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - JWT_SECRET=development_secret_key
    env_file:
      - ./.env
    depends_on:
      - mongo

  # Frontend service
  frontend:
    build: 
      context: ./frontend
      target: development
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000
      - NEXTAUTH_URL=http://localhost:3000
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET:-}
      - NEXTAUTH_DEBUG=true
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID:-}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET:-}
    env_file:
      - ./.env
    stdin_open: true
    # Using the default npm run dev which already includes turbopack
    command: sh -c "node ensure-env.js && npm run dev -- --hostname 0.0.0.0"

  # MongoDB service remains unchanged
  mongo:
    image: mongo:5.0
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db

volumes:
  mongo-data:

--- File: frontend/.dockerignore ---

node_modules
.next
npm-debug.log
build
.git
.github

--- File: frontend/.eslintrc.json ---

{
  "extends": ["next/core-web-vitals"],
  "rules": {
    "@typescript-eslint/no-unused-vars": ["error", { 
      "argsIgnorePattern": "^_",
      "varsIgnorePattern": "^_",
      "caughtErrorsIgnorePattern": "^_"
    }]
  }
}

--- File: frontend/Dockerfile ---

FROM node:20-alpine AS base

WORKDIR /app

# Copy package files
COPY package.json package-lock.json* ./

# For development, this is all we need to do before mounting volumes
FROM base AS development
RUN npm install
# Development container will mount the source code volume
CMD ["npm", "run", "dev", "--", "--hostname", "0.0.0.0"]

# For production, we build the application
FROM base AS production
RUN npm ci
COPY . .
RUN npm run build
# Use only what's needed for production
RUN npm prune --production
CMD ["node", "server.js"]

--- File: frontend/ensure-env.js ---

// Simple script to verify environment variables
const fs = require('fs');
const path = require('path');

// Check and log critical environment variables
console.log('Environment Variable Check:');
console.log('=========================');
console.log('NEXTAUTH_SECRET:', process.env.NEXTAUTH_SECRET ? '✅ Set' : '❌ Missing');
console.log('NEXTAUTH_URL:', process.env.NEXTAUTH_URL ? '✅ Set' : '❌ Missing');
console.log('GOOGLE_CLIENT_ID:', process.env.GOOGLE_CLIENT_ID ? '✅ Set' : '❌ Missing');
console.log('GOOGLE_CLIENT_SECRET:', process.env.GOOGLE_CLIENT_SECRET ? '✅ Set' : '❌ Missing');
console.log('NEXTAUTH_DEBUG:', process.env.NEXTAUTH_DEBUG ? '✅ Set' : '❌ Missing');
console.log('=========================');

// Create a temporary .env.local file if needed
if (!process.env.GOOGLE_CLIENT_ID || !process.env.GOOGLE_CLIENT_SECRET) {
  console.warn('Warning: Missing OAuth credentials in environment variables.');
  console.warn('Checking .env file...');
  
  try {
    const envPath = path.join(process.cwd(), '.env');
    if (fs.existsSync(envPath)) {
      const envContent = fs.readFileSync(envPath, 'utf8');
      const envLines = envContent.split('\n');
      const envVars = {};
      
      // Parse .env file
      envLines.forEach(line => {
        const match = line.match(/^([^=]+)=(.*)$/);
        if (match) {
          const key = match[1].trim();
          const value = match[2].trim();
          envVars[key] = value;
        }
      });
      
      // Log what was found in .env
      console.log('Values from .env file:');
      console.log('GOOGLE_CLIENT_ID in .env:', envVars.GOOGLE_CLIENT_ID ? '✅ Found' : '❌ Missing');
      console.log('GOOGLE_CLIENT_SECRET in .env:', envVars.GOOGLE_CLIENT_SECRET ? '✅ Found' : '❌ Missing');
    } else {
      console.warn('No .env file found');
    }
  } catch (error) {
    console.error('Error reading .env file:', error);
  }
}

--- File: frontend/next.config.ts ---

// frontend/next.config.ts (Should already be correct)
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  async rewrites() {
    return [
      // Keep NextAuth routes on the frontend
      {
        source: '/api/auth/:path*',
        destination: '/api/auth/:path*', // Internal routing
      },
      // Forward other API routes to the backend
      {
        source: '/api/:path*', // This catches /api/conversations, /api/chat, etc.
        destination: process.env.NODE_ENV === 'production'
          ? 'https://production-backend-url.com/:path*'
          // Use service name from docker-compose in development
          : 'http://backend:8000/:path*',
      },
    ];
  },
  reactStrictMode: true,
  experimental: {},
  images: {
    // Add image domains if user profiles use external images (e.g., Google avatars)
    domains: ['localhost', 'lh3.googleusercontent.com'], // Example for Google images
  }
};

export default nextConfig;

--- File: frontend/package.json ---

{
  "name": "frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev --turbopack",
    "build": "next build",
    "start": "next start",
    "lint": "next lint",
    "test": "jest",
    "test:watch": "jest --watch"
  },
  "dependencies": {
    "next": "^15.2.4",
    "next-auth": "^4.24.11",
    "react": "^19.0.0",
    "react-dom": "^19.0.0"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@tailwindcss/postcss": "^4",
    "@testing-library/jest-dom": "^6.6.3",
    "@testing-library/react": "^16.2.0",
    "@testing-library/user-event": "^14.6.1",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.2.0",
    "jest": "^29.7.0",
    "jest-environment-jsdom": "^29.7.0",
    "tailwindcss": "^4",
    "typescript": "^5"
  }
}


--- File: frontend/run_tests.sh ---

#!/bin/bash

# Run frontend tests
echo "Running frontend tests..."
npm test

# Exit with the test result status code
exit $?

--- File: frontend/src/__tests__/Auth.test.tsx ---

import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { signIn, useSession } from 'next-auth/react';
import SignIn from '../app/auth/signin/page';

// Mock the next-auth/react module
jest.mock('next-auth/react', () => ({
  signIn: jest.fn(),
  useSession: jest.fn(),
}));

describe('Authentication', () => {
  // Reset mocks before each test
  beforeEach(() => {
    jest.clearAllMocks();
    (useSession as jest.Mock).mockReturnValue({
      data: null,
      status: 'unauthenticated',
    });
  });

  test('Sign In page renders correctly', () => {
    render(<SignIn />);
    
    // Check for sign in heading
    expect(screen.getByText('Sign in to ThreadFlow')).toBeInTheDocument();
    
    // Check for Google sign in button
    expect(screen.getByText('Sign in with Google')).toBeInTheDocument();
  });

  test('Google sign in button calls signIn function', async () => {
    render(<SignIn />);
    
    // Find and click the Google sign in button
    const signInButton = screen.getByText('Sign in with Google');
    fireEvent.click(signInButton);
    
    // Check if signIn was called with the right parameters
    await waitFor(() => {
      expect(signIn).toHaveBeenCalledWith('google', { callbackUrl: '/' });
    });
  });

  test('Shows loading state when signing in', async () => {
    render(<SignIn />);
    
    // Find and click the Google sign in button
    const signInButton = screen.getByText('Sign in with Google');
    fireEvent.click(signInButton);
    
    // Wait for loading state to appear
    await waitFor(() => {
      expect(screen.getByText('Signing in...')).toBeInTheDocument();
    });
  });
});

--- File: frontend/src/__tests__/Chat.test.tsx ---

import React from 'react';
import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import Chat from '../app/chat/page';

// Mock fetch requests
global.fetch = jest.fn();

// Mock response for models endpoint
const mockModelsResponse = {
  google: {
    available: true,
    models: [
      {
        id: 'gemini-2.5-pro-exp-03-25',
        name: 'Gemini 2.5 Pro Experimental',
        description: 'Latest experimental Gemini model with advanced capabilities'
      },
      {
        id: 'gemini-2.0-flash',
        name: 'Gemini 2.0 Flash',
        description: 'Fast, efficient model with strong performance'
      }
    ]
  },
  anthropic: {
    available: true,
    models: [
      {
        id: 'claude-3-7-sonnet-20250219',
        name: 'Claude 3.7 Sonnet',
        description: 'Latest and most capable Claude Sonnet model'
      },
      {
        id: 'claude-3-5-sonnet-20241022',
        name: 'Claude 3.5 Sonnet v2',
        description: 'Balanced performance and cost Sonnet model'
      }
    ]
  },
  openai: {
    available: true,
    models: [
      {
        id: 'gpt-4o',
        name: 'GPT-4o',
        description: "OpenAI's latest multimodal model with optimal performance"
      }
    ]
  }
};

// Mock chat response
const mockChatResponse = {
  response: 'This is a test response from the AI model.'
};

// Mock fetch implementation
beforeEach(() => {
  jest.resetAllMocks();
  
  // Mock fetch to return different responses based on URL
  (global.fetch as jest.Mock).mockImplementation((url) => {
    if (url === 'http://localhost:8000/models') {
      return Promise.resolve({
        ok: true,
        json: () => Promise.resolve(mockModelsResponse)
      });
    } else if (url === 'http://localhost:8000/chat') {
      return Promise.resolve({
        ok: true,
        json: () => Promise.resolve(mockChatResponse)
      });
    }
    
    return Promise.reject(new Error(`Unhandled request to ${url}`));
  });
});

describe('Chat Component', () => {
  test('renders chat interface', async () => {
    render(<Chat />);
    
    // Verify the page title is displayed
    expect(screen.getByText('Chat Page')).toBeInTheDocument();
    
    // Verify initial placeholder text
    expect(screen.getByText('Your response will appear here')).toBeInTheDocument();
    
    // Wait for models to load
    await waitFor(() => {
      expect(global.fetch).toHaveBeenCalledWith('http://localhost:8000/models');
    });
  });
  
  test('displays provider and model dropdowns', async () => {
    render(<Chat />);
    
    // Wait for models to load
    await waitFor(() => {
      expect(global.fetch).toHaveBeenCalledWith('http://localhost:8000/models');
    });
    
    // Check that provider dropdown has all options
    const providerDropdown = screen.getByLabelText('Provider');
    expect(providerDropdown).toBeInTheDocument();
    
    // Check that model dropdown is populated
    const modelDropdown = screen.getByLabelText('Model');
    expect(modelDropdown).toBeInTheDocument();
  });
  
  test('sends message and displays response', async () => {
    const user = userEvent.setup();
    render(<Chat />);
    
    // Wait for models to load
    await waitFor(() => {
      expect(global.fetch).toHaveBeenCalledWith('http://localhost:8000/models');
    });
    
    // Type a message
    const textarea = screen.getByPlaceholderText('Type your message here...');
    await user.type(textarea, 'Hello AI!');
    
    // Submit the form
    const sendButton = screen.getByRole('button', { name: /send message/i });
    await user.click(sendButton);
    
    // Verify the fetch was called with correct data
    await waitFor(() => {
      expect(global.fetch).toHaveBeenCalledWith('http://localhost:8000/chat', expect.objectContaining({
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: expect.stringContaining('Hello AI!'),
      }));
    });
    
    // Verify response is displayed
    await waitFor(() => {
      expect(screen.getByText('This is a test response from the AI model.')).toBeInTheDocument();
    });
  });
  
  test('shows model description for default provider', async () => {
    render(<Chat />);
    
    // Wait for models to load
    await waitFor(() => {
      expect(global.fetch).toHaveBeenCalledWith('http://localhost:8000/models');
    });
    
    // Just test that the default model description is displayed correctly
    // This is more reliable than trying to change providers
    await waitFor(() => {
      const modelDescription = screen.getByText(/Latest experimental Gemini model/i);
      expect(modelDescription).toBeInTheDocument();
    });
  });
  
  test('handles API errors', async () => {
    // Mock an error response
    (global.fetch as jest.Mock).mockImplementation((url) => {
      if (url === 'http://localhost:8000/models') {
        return Promise.resolve({
          ok: true,
          json: () => Promise.resolve(mockModelsResponse)
        });
      } else if (url === 'http://localhost:8000/chat') {
        return Promise.resolve({
          ok: false,
          status: 500,
          statusText: 'Internal Server Error'
        });
      }
      return Promise.reject(new Error(`Unhandled request to ${url}`));
    });
    
    const user = userEvent.setup();
    render(<Chat />);
    
    // Wait for models to load and for the dropdown to be populated
    await waitFor(() => {
      expect(global.fetch).toHaveBeenCalledWith('http://localhost:8000/models');
      // Make sure dropdown options are loaded
      expect(screen.queryByText('Loading...')).not.toBeInTheDocument();
    });
    
    // Type a message
    const textarea = screen.getByPlaceholderText('Type your message here...');
    await user.type(textarea, 'Hello AI!');
    
    // Submit the form
    const sendButton = screen.getByRole('button', { name: /send message/i });
    await user.click(sendButton);
    
    // Verify that the error message is shown in the response area
    await waitFor(() => {
      // Check for either the error response in the main response area
      // or the error message in the error box
      const responseText = screen.getByText(/Error connecting to the server/i);
      expect(responseText).toBeInTheDocument();
      
      // In a real scenario, we'd also have an error message above, but
      // for testing purposes just check that the response text has the error
    });
  });
});

--- File: frontend/src/__tests__/ErrorHandlingTest.tsx ---

import React from 'react';
import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';

// This is a simplified test component just for error handling
function ErrorHandlingDemo() {
  const [error, setError] = React.useState<string | null>(null);
  const [response, setResponse] = React.useState<string>('');
  
  const triggerError = async () => {
    try {
      throw new Error('Test error message');
    } catch (err) {
      setResponse('Error connecting to the server. Please try again.');
      setError(err instanceof Error ? err.message : String(err));
    }
  };
  
  return (
    <div>
      {error && (
        <div className="error-box" role="alert">
          <p>Error: {error}</p>
        </div>
      )}
      
      <div className="response-area">
        <p>{response}</p>
      </div>
      
      <button onClick={triggerError}>Trigger Error</button>
    </div>
  );
}

describe('Error Handling', () => {
  test('displays error message in both locations', async () => {
    const user = userEvent.setup();
    render(<ErrorHandlingDemo />);
    
    // Trigger the error
    const button = screen.getByRole('button', { name: /trigger error/i });
    await user.click(button);
    
    // Check for error in the error box
    await waitFor(() => {
      const errorBox = screen.getByRole('alert');
      expect(errorBox).toBeInTheDocument();
      expect(screen.getByText(/Error: Test error message/i)).toBeInTheDocument();
    });
    
    // Check for error message in the response area
    await waitFor(() => {
      const responseText = screen.getByText(/Error connecting to the server/i);
      expect(responseText).toBeInTheDocument();
    });
  });
});

--- File: frontend/src/__tests__/ModelSelection.test.tsx ---

import { findBestModelForProvider, getModelDescription} from '../utils/modelUtils';
import { ModelsResponse } from '../types/models';

// This is just a focused test of the model selection functionality
// without the complexity of React rendering

const mockModelsResponse: ModelsResponse = {
  google: {
    available: true,
    models: [
      {
        id: 'gemini-2.5-pro-exp-03-25',
        name: 'Gemini 2.5 Pro Experimental',
        description: 'Latest experimental Gemini model with advanced capabilities'
      },
      {
        id: 'gemini-2.0-flash',
        name: 'Gemini 2.0 Flash',
        description: 'Fast, efficient model with strong performance'
      }
    ]
  },
  anthropic: {
    available: true,
    models: [
      {
        id: 'claude-3-7-sonnet-20250219',
        name: 'Claude 3.7 Sonnet',
        description: 'Latest and most capable Claude Sonnet model'
      },
      {
        id: 'claude-3-5-sonnet-20241022',
        name: 'Claude 3.5 Sonnet v2',
        description: 'Balanced performance and cost Sonnet model'
      }
    ]
  },
  openai: {
    available: true,
    models: [
      {
        id: 'gpt-4o',
        name: 'GPT-4o',
        description: "OpenAI's latest multimodal model with optimal performance"
      }
    ]
  }
};

describe('Model Selection UI Logic', () => {
  test('when changing from Google to Anthropic, Claude 3.7 Sonnet should be selected', () => {
    // Simulate changing provider from Google to Anthropic
    const initialProvider = 'google';
    const newProvider = 'anthropic';
    
    // This would be the default Google model
    expect(findBestModelForProvider(mockModelsResponse, initialProvider))
      .toBe('gemini-2.5-pro-exp-03-25');
    
    // This would be the selected Anthropic model after change
    expect(findBestModelForProvider(mockModelsResponse, newProvider))
      .toBe('claude-3-7-sonnet-20250219');
    
    // Verify the description is what we expect
    const modelId = findBestModelForProvider(mockModelsResponse, newProvider);
    const description = getModelDescription(mockModelsResponse, newProvider, modelId!);
    expect(description).toBe('Latest and most capable Claude Sonnet model');
  });
  
  test('when changing from Google to OpenAI, GPT-4o should be selected', () => {
    // Simulate changing provider from Google to OpenAI
    const initialProvider = 'google';
    const newProvider = 'openai';
    
    // This would be the default Google model
    expect(findBestModelForProvider(mockModelsResponse, initialProvider))
      .toBe('gemini-2.5-pro-exp-03-25');
    
    // This would be the selected OpenAI model after change
    expect(findBestModelForProvider(mockModelsResponse, newProvider))
      .toBe('gpt-4o');
    
    // Verify the description is what we expect
    const modelId = findBestModelForProvider(mockModelsResponse, newProvider);
    const description = getModelDescription(mockModelsResponse, newProvider, modelId!);
    expect(description).toBe("OpenAI's latest multimodal model with optimal performance");
  });
});

--- File: frontend/src/__tests__/modelUtils.test.ts ---

import { findBestModelForProvider, getModelDescription, isProviderAvailable } from '../utils/modelUtils';
import { ModelsResponse } from '../types/models';

const mockModelsResponse: ModelsResponse = {
  google: {
    available: true,
    models: [
      {
        id: 'gemini-2.5-pro-exp-03-25',
        name: 'Gemini 2.5 Pro Experimental',
        description: 'Latest experimental Gemini model with advanced capabilities'
      },
      {
        id: 'gemini-2.0-flash',
        name: 'Gemini 2.0 Flash',
        description: 'Fast, efficient model with strong performance'
      }
    ]
  },
  anthropic: {
    available: true,
    models: [
      {
        id: 'claude-3-7-sonnet-20250219',
        name: 'Claude 3.7 Sonnet',
        description: 'Latest and most capable Claude Sonnet model'
      },
      {
        id: 'claude-3-5-sonnet-20241022',
        name: 'Claude 3.5 Sonnet v2',
        description: 'Balanced performance and cost Sonnet model'
      }
    ]
  },
  openai: {
    available: true,
    models: [
      {
        id: 'gpt-4o',
        name: 'GPT-4o',
        description: "OpenAI's latest multimodal model with optimal performance"
      }
    ]
  },
  unavailable: {
    available: false,
    models: []
  }
};

describe('Model Utilities', () => {
  describe('findBestModelForProvider', () => {
    test('returns the best Anthropic model', () => {
      const result = findBestModelForProvider(mockModelsResponse, 'anthropic');
      expect(result).toBe('claude-3-7-sonnet-20250219');
    });

    test('returns the best Google model', () => {
      const result = findBestModelForProvider(mockModelsResponse, 'google');
      expect(result).toBe('gemini-2.5-pro-exp-03-25');
    });

    test('returns the best OpenAI model', () => {
      const result = findBestModelForProvider(mockModelsResponse, 'openai');
      expect(result).toBe('gpt-4o');
    });

    test('returns first model if preferred model not found', () => {
      // Create a modified response without the preferred model
      const modifiedResponse = {
        ...mockModelsResponse,
        google: {
          available: true,
          models: [
            {
              id: 'gemini-2.0-flash',
              name: 'Gemini 2.0 Flash',
              description: 'Fast, efficient model with strong performance'
            }
          ]
        }
      };
      
      const result = findBestModelForProvider(modifiedResponse, 'google');
      expect(result).toBe('gemini-2.0-flash');
    });

    test('returns undefined for unavailable provider', () => {
      const result = findBestModelForProvider(mockModelsResponse, 'unavailable');
      expect(result).toBeUndefined();
    });

    test('returns undefined for null models', () => {
      const result = findBestModelForProvider(null, 'google');
      expect(result).toBeUndefined();
    });
  });

  describe('getModelDescription', () => {
    test('returns description for a specific model', () => {
      const result = getModelDescription(
        mockModelsResponse, 
        'anthropic', 
        'claude-3-7-sonnet-20250219'
      );
      expect(result).toBe('Latest and most capable Claude Sonnet model');
    });

    test('returns empty string for non-existent model', () => {
      const result = getModelDescription(
        mockModelsResponse, 
        'anthropic', 
        'non-existent-model'
      );
      expect(result).toBe('');
    });

    test('returns empty string for non-existent provider', () => {
      const result = getModelDescription(
        mockModelsResponse, 
        'non-existent', 
        'claude-3-7-sonnet-20250219'
      );
      expect(result).toBe('');
    });

    test('returns empty string for null models', () => {
      const result = getModelDescription(
        null, 
        'anthropic', 
        'claude-3-7-sonnet-20250219'
      );
      expect(result).toBe('');
    });
  });

  describe('isProviderAvailable', () => {
    test('returns true for available provider', () => {
      const result = isProviderAvailable(mockModelsResponse, 'google');
      expect(result).toBe(true);
    });

    test('returns false for unavailable provider', () => {
      const result = isProviderAvailable(mockModelsResponse, 'unavailable');
      expect(result).toBe(false);
    });

    test('returns false for non-existent provider', () => {
      const result = isProviderAvailable(mockModelsResponse, 'non-existent');
      expect(result).toBe(false);
    });

    test('returns false for null models', () => {
      const result = isProviderAvailable(null, 'google');
      expect(result).toBe(false);
    });
  });
});

--- File: frontend/src/app/ClientProviders.tsx ---

// src/app/ClientProviders.tsx
"use client";

import { SessionProvider } from "next-auth/react";

export function ClientProviders({ children }: { children: React.ReactNode }) {
  return (
    <SessionProvider basePath="/api/auth">
      {children}
    </SessionProvider>
  );
}


--- File: frontend/src/app/about/page.tsx ---

"use client";

import Link from "next/link";

export default function About() {
  return (
    <div className="flex flex-col items-center justify-center min-h-screen p-8 max-w-3xl mx-auto">
      <h1 className="text-3xl font-bold mb-8">About ThreadFlow</h1>

      <p className="text-lg leading-relaxed mb-10 text-center">
        ThreadFlow is a branching chat interface designed for AI-powered conversations, enabling users to explore tangential ideas and manage complex discussions without losing context. It provides an intuitive way to orchestrate multiple AI models, allowing users to compare and combine outputs effortlessly. With ThreadFlow, each message can branch into sub-threads, keeping side discussions separate while maintaining relevance. Users can select which branches contribute to the conversation, ensuring focused responses. Advanced search and collaboration features, including shareable conversation trees and export options, enhance productivity. The interface is built with a React-based frontend and a FastAPI-powered backend, integrating LLMs for dynamic interactions. Designed for both technical and non-technical users, ThreadFlow streamlines AI-assisted workflows with an intuitive, scalable, and interactive experience.
      </p>

      <Link 
        className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5"
        href="/"
      >
        Back to Home
      </Link>
    </div>
  );
}


--- File: frontend/src/app/api/auth/[...nextauth]/route.ts ---

import NextAuth from "next-auth";
import type { NextAuthOptions } from "next-auth";
import GoogleProvider from "next-auth/providers/google";

// Environment variables should be properly set in .env file

// 1. Configure NextAuth options
export const authOptions: NextAuthOptions = {
  secret: process.env.NEXTAUTH_SECRET, // Required in production
  debug: process.env.NEXTAUTH_DEBUG === "true",
  providers: [
    GoogleProvider({
      clientId: process.env.GOOGLE_CLIENT_ID ?? "",
      clientSecret: process.env.GOOGLE_CLIENT_SECRET ?? "",
    }),
  ],
  // Add session configuration
  session: {
    strategy: "jwt",
    maxAge: 30 * 24 * 60 * 60, // 30 days
  },
  // Add callbacks for JWT and session handling
  callbacks: {
    async jwt({ token, account, profile }) {
      // Persist the OAuth access_token to the token right after signin
      if (account) {
        token.accessToken = account.access_token;
        
        // Store user in database through our API
        try {
          const apiUrl = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';
          const response = await fetch(`${apiUrl}/users`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              id: token.sub,
              email: token.email,
              name: token.name,
              image: token.picture,
            }),
          });
          
          if (!response.ok) {
            console.error('Failed to store user in database', await response.text());
          }
        } catch (error) {
          console.error('Error storing user in database:', error);
        }
      }
      return token;
    },
    async session({ session, token }) {
      // Send properties to the client
      session.accessToken = token.accessToken as string;
      
      // Add user ID from OAuth to the session
      if (session.user) {
        session.user.id = token.sub;
      }
      
      return session;
    },
  },
  pages: {
    signIn: '/auth/signin',
    error: '/auth/error',
  },
};

// 2. Create the NextAuth handler
const handler = NextAuth(authOptions);

// 3. Export as GET and POST for the App Router
export { handler as GET, handler as POST };


--- File: frontend/src/app/auth/error/page.tsx ---

"use client";

import { useSearchParams } from "next/navigation";
import Link from "next/link";

export default function ErrorPage() {
  const searchParams = useSearchParams();
  const error = searchParams.get("error");

  // Map error codes to user-friendly messages
  const errorMessages: Record<string, string> = {
    Configuration: "There is a problem with the server configuration.",
    AccessDenied: "You do not have permission to sign in.",
    Verification: "The verification link may have been used or has expired.",
    OAuthSignin: "Error in the OAuth sign-in process.",
    OAuthCallback: "Error in the OAuth callback process.",
    OAuthCreateAccount: "Could not create an OAuth provider account.",
    EmailCreateAccount: "Could not create an email provider account.",
    Callback: "Error in the OAuth callback.",
    OAuthAccountNotLinked: "This account is already linked to another sign-in method.",
    EmailSignin: "Error sending the verification email.",
    CredentialsSignin: "The sign in failed. Check the details you provided are correct.",
    SessionRequired: "Please sign in to access this page.",
    default: "An unknown error occurred during authentication."
  };

  // Get the appropriate error message
  const errorMessage = error && errorMessages[error] 
    ? errorMessages[error]
    : errorMessages.default;

  return (
    <div className="flex min-h-screen flex-col items-center justify-center p-6">
      <div className="w-full max-w-md space-y-8 rounded-lg bg-white p-8 shadow-md">
        <div className="text-center">
          <h1 className="text-3xl font-bold text-red-600">Authentication Error</h1>
          <div className="mt-4">
            <p className="text-gray-700">{errorMessage}</p>
            <p className="mt-2 text-sm text-gray-500">
              Error code: {error || "unknown"}
            </p>
          </div>
          <div className="mt-6">
            <Link 
              href="/auth/signin"
              className="inline-flex items-center rounded-md border border-transparent bg-indigo-600 px-4 py-2 text-sm font-medium text-white shadow-sm hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2"
            >
              Try Again
            </Link>
          </div>
        </div>
      </div>
    </div>
  );
}

--- File: frontend/src/app/auth/signin/page.tsx ---

"use client";

import { signIn } from "next-auth/react";
import { useState } from "react";

export default function SignIn() {
  const [isLoading, setIsLoading] = useState(false);

  const handleGoogleSignIn = async () => {
    setIsLoading(true);
    await signIn("google", { callbackUrl: "/" });
    setIsLoading(false);
  };

  return (
    <div className="flex min-h-screen flex-col items-center justify-center p-6">
      <div className="w-full max-w-md space-y-8 rounded-lg bg-white p-8 shadow-md">
        <div className="text-center">
          <h1 className="text-3xl font-bold">Sign in to ThreadFlow</h1>
          <p className="mt-2 text-gray-600">
            Connect with your favorite AI models
          </p>
        </div>

        <div className="mt-8 space-y-4">
          <button
            onClick={handleGoogleSignIn}
            disabled={isLoading}
            className="flex w-full items-center justify-center rounded-md border border-gray-300 bg-white px-4 py-2 text-gray-700 shadow-sm hover:bg-gray-50 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2"
          >
            <svg
              className="mr-2 h-5 w-5"
              viewBox="0 0 24 24"
              fill="currentColor"
              xmlns="http://www.w3.org/2000/svg"
            >
              <path
                d="M12.24 10.285V14.4h6.806c-.275 1.765-2.056 5.174-6.806 5.174-4.095 0-7.439-3.389-7.439-7.574s3.345-7.574 7.439-7.574c2.33 0 3.891.989 4.785 1.849l3.254-3.138C18.189 1.186 15.479 0 12.24 0c-6.635 0-12 5.365-12 12s5.365 12 12 12c6.926 0 11.52-4.869 11.52-11.726 0-.788-.085-1.39-.189-1.989H12.24z"
              />
            </svg>
            {isLoading ? "Signing in..." : "Sign in with Google"}
          </button>
        </div>
      </div>
    </div>
  );
}

--- File: frontend/src/app/chat/page.tsx ---

"use client";

import Link from "next/link";
import { useState, useEffect, useCallback } from "react";
import { useSession } from "next-auth/react";
import { ModelsResponse, ProviderConfig, ConversationMetadata, Conversation, MessageItem, ChatApiResponse} from "@/types/models";
import { findBestModelForProvider, getModelDescription, isProviderAvailable } from "@/utils/modelUtils";

interface SidebarProps {
  metadataList: ConversationMetadata[];
  activeId: string | null;
  onSelect: (id: string) => void;
  onCreateNew: () => void; // Callback to create a new root chat
  isLoading: boolean;
}

function ChatSidebar({ metadataList, activeId, onSelect, onCreateNew, isLoading }: SidebarProps) {
  const sortedList = metadataList
      ? [...metadataList].sort((a, b) => new Date(b.updated_at).getTime() - new Date(a.updated_at).getTime())
      : null;

  return (
      <div className="w-64 pr-4 border-r border-gray-300 dark:border-gray-700 flex flex-col h-full overflow-y-auto">
           <button
              onClick={onCreateNew}
              className="w-full mb-4 p-2 bg-blue-500 text-white rounded hover:bg-blue-600 disabled:opacity-50"
              disabled={isLoading}
          >
              + New Chat
          </button>
          {isLoading && <p className="text-sm text-gray-500">Loading chats...</p>}
          {!isLoading && !sortedList?.length && <p className="text-sm text-gray-500">No conversations yet.</p>}
          {sortedList?.map(meta => (
              <button
                  key={meta.id}
                  onClick={() => onSelect(meta.id)}
                  className={`w-full text-left p-2 mb-1 rounded text-sm truncate ${
                      activeId === meta.id
                          ? "bg-blue-100 dark:bg-blue-800 font-semibold"
                          : "hover:bg-gray-100 dark:hover:bg-gray-700"
                  }`}
                  title={meta.title} // Show full title on hover
              >
                  {/* Add indicator for branches? */}
                  {meta.parent_conversation_id && <span className="mr-1"> L </span>}
                  {meta.title}
              </button>
          ))}
      </div>
  );
}

export default function Chat() {
  const { data: session, status } = useSession();
  // --- Existing State ---
  const userId = session?.user?.id;
  const [userInput, setUserInput] = useState<string>("");
  const [selectedProvider, setSelectedProvider] = useState<string>("google");
  const [selectedModelId, setSelectedModelId] = useState<string>(""); // Initialize empty, set after models load
  const [models, setModels] = useState<ModelsResponse | null>(null);
  const [isLoadingModels, setIsLoadingModels] = useState<boolean>(true); // Start true

  // --- NEW State for Branching ---
  const [conversationMetadataList, setConversationMetadataList] = useState<ConversationMetadata[] | null>(null);
  const [activeConversationContent, setActiveConversationContent] = useState<Conversation | null>(null);
  const [activeConversationId, setActiveConversationId] = useState<string | null>(null);
  const [isLoadingMetadata, setIsLoadingMetadata] = useState<boolean>(false);
  const [isLoadingContent, setIsLoadingContent] = useState<boolean>(false);
  const [isLoadingResponse, setIsLoadingResponse] = useState<boolean>(false); // For chat submit button
  const [error, setError] = useState<string | null>(null); // General error state

  // Fetch available models on component mount
  useEffect(() => {
    const fetchModels = async () => {
      setIsLoadingModels(true);
      setError(null);
      try {
        // Use relative path for API routes handled by Next.js rewrite
        const response = await fetch("/api/models");
        if (!response.ok) {
          throw new Error(`Failed to fetch models: ${response.status}`);
        }
        const data: ModelsResponse = await response.json();
        setModels(data);

        // Find the first available provider and its best model to set as default
        let defaultProvider = "google"; // Default fallback
        let defaultModel = "";
        const providers = Object.keys(data);
        for (const provider of providers) {
            if (isProviderAvailable(data, provider)) {
                defaultProvider = provider;
                defaultModel = findBestModelForProvider(data, provider) || "";
                break; // Found the first available, stop looking
            }
        }
        setSelectedProvider(defaultProvider);
        setSelectedModelId(defaultModel);

      } catch (err) {
        console.error("Error fetching models:", err);
        setError(`Failed to load models: ${err instanceof Error ? err.message : String(err)}`);
        // Keep default provider/model empty or fallback
        setSelectedProvider("google");
        setSelectedModelId("");
      } finally {
        setIsLoadingModels(false);
      }
    };
    fetchModels();
  }, []);
  const fetchMetadata = useCallback(async () => {
    if (!userId) return; // Need user ID

    setIsLoadingMetadata(true);
    setError(null);
    try {
      // Use relative path for API routes handled by Next.js rewrite
      // Pass user_id as query parameter
      const response = await fetch(`/api/conversations?user_id=${userId}`);
      if (!response.ok) {
          if (response.status === 401 || response.status === 403) {
              // Handle auth errors, maybe sign out user?
              setError("Authentication error fetching conversations.");
          } else {
             throw new Error(`Failed to fetch conversation list: ${response.status}`);
          }
          setConversationMetadataList(null); // Clear list on error
          return; // Stop processing
      }
      const data: ConversationMetadata[] = await response.json();
      setConversationMetadataList(data);

      // Optional: If no active chat, select the most recent one automatically
      // if (!activeConversationId && data.length > 0) {
      //    setActiveConversationId(data[0].id); // data should be sorted by backend
      // }

    } catch (err) {
      console.error("Error fetching conversation metadata:", err);
      setError(`Failed to load conversation list: ${err instanceof Error ? err.message : String(err)}`);
      setConversationMetadataList(null);
    } finally {
      setIsLoadingMetadata(false);
    }
  }, [userId]); // Dependency: userId

  const fetchFullConversation = useCallback(async (id: string) => {
    if (!userId) return; // Need user ID for ownership check

    setIsLoadingContent(true);
    setError(null);
    // Optimistically keep old content while loading? Or clear it? Clear for now.
    // setActiveConversationContent(null);
    try {
      // Pass user_id as query parameter for ownership check on backend
      const response = await fetch(`/api/conversations/${id}?user_id=${userId}`);
      if (!response.ok) {
        if (response.status === 404) {
             setError("Conversation not found.");
             setActiveConversationId(null); // Deselect if not found
        } else if (response.status === 403) {
             setError("You don't have permission to view this conversation.");
             setActiveConversationId(null); // Deselect if forbidden
        } else {
            throw new Error(`Failed to fetch conversation details: ${response.status}`);
        }
        setActiveConversationContent(null); // Clear content on error
        return;
      }
      const data: Conversation = await response.json();
      setActiveConversationContent(data);
    } catch (err) {
      console.error("Error fetching full conversation:", err);
      setError(`Failed to load conversation: ${err instanceof Error ? err.message : String(err)}`);
      setActiveConversationContent(null);
      setActiveConversationId(null); // Deselect on error
    } finally {
      setIsLoadingContent(false);
    }
  }, [userId]); // Dependency: userId


  // --- Handlers ---
  const handleSelectConversation = (id: string) => {
      if (id !== activeConversationId) {
          setActiveConversationId(id);
          // fetchFullConversation will be triggered by the useEffect watching activeConversationId
          setError(null); // Clear previous errors on selection change
      }
  };

  // Clears the active selection to signal intent for a new chat
  // The actual creation happens when the user sends the first message via handleSubmit
  const handleCreateNewChat = () => {
       setActiveConversationId(null);
       setActiveConversationContent(null); // Clear content
       setUserInput(""); // Clear input
       setError(null);
       // Focus the textarea?
  };
  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!userInput.trim() || !selectedModelId || !userId || isLoadingResponse || isLoadingContent) return;

    setIsLoadingResponse(true);
    setError(null);

    const currentConversationId = activeConversationId; // Capture current ID before potential changes

    // Optimistic UI Update (Optional but improves UX)
    const tempUserMessageId = `temp-user-${Date.now()}`;
    const optimisticUserMessage: MessageItem = {
         id: tempUserMessageId,
         role: "user",
         content: userInput,
         timestamp: new Date().toISOString()
    };
    if (activeConversationContent) {
        setActiveConversationContent(prev => prev ? { ...prev, messages: [...prev.messages, optimisticUserMessage] } : null);
    } else {
         // If starting a new chat, create temporary optimistic content
         setActiveConversationContent({
              id: "temp-new-chat", // Temporary ID
              user_id: userId,
              title: userInput.substring(0, 30) + "...",
              messages: [optimisticUserMessage],
              created_at: new Date().toISOString(),
              updated_at: new Date().toISOString(),
              parent_conversation_id: null,
              branch_point_message_id: null
         });
    }
    const messageToSend = userInput; // Store user input before clearing
    setUserInput(""); // Clear input field immediately


    try {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: messageToSend,
          provider: selectedProvider,
          model_id: selectedModelId,
          user_id: userId,
          conversation_id: currentConversationId // Send null/undefined if starting new chat
        }),
      });

      if (!response.ok) {
        // Rollback optimistic update on error?
        if (activeConversationContent?.messages.at(-1)?.id === tempUserMessageId) {
            setActiveConversationContent(prev => prev ? { ...prev, messages: prev.messages.slice(0, -1) } : null);
        }
        const errorData = await response.json().catch(() => ({ detail: "Unknown server error" }));
        throw new Error(`Server error ${response.status}: ${errorData.detail || response.statusText}`);
      }

      const data: ChatApiResponse = await response.json();

      // --- Update State with Real Data ---
      const newUserMessage: MessageItem = {
          ...optimisticUserMessage,
          id: data.user_message_id, // Use real ID from backend
      };
      const assistantMessage: MessageItem = {
          id: data.assistant_message_id,
          role: "assistant",
          content: data.response,
          timestamp: new Date().toISOString() // Backend doesn't return this, use client time or modify backend
      };

      // If it was a new chat, we now have the real ID and potentially title
      const realConversationId = data.conversation_id;
      const isNewConversation = !currentConversationId;


      // Update Active Conversation Content
      setActiveConversationContent(prev => {
          if (!prev) return null; // Should not happen if optimistic update worked

          // Find and replace optimistic message or just append if optimistic failed/disabled
          const messages = prev.messages.filter(m => m.id !== tempUserMessageId);
          messages.push(newUserMessage);
          messages.push(assistantMessage);

          return {
              ...prev,
              id: realConversationId, // Update ID if it was new/temporary
              messages: messages,
              updated_at: new Date().toISOString(), // Update timestamp
               // Title might change on first message, backend doesn't return it, refetch metadata?
          };
      });

      // Update Metadata List
      setConversationMetadataList(prevList => {
          if (!prevList) return isNewConversation ? [] : null; // Should fetch if null

          const existingIndex = prevList.findIndex(meta => meta.id === realConversationId);
          const now = new Date().toISOString();

          if (existingIndex !== -1) {
              // Update existing metadata item
              const updatedMeta = { ...prevList[existingIndex], updated_at: now };
               // Maybe update title if backend logic changes it? For now, just timestamp.
              const newList = [...prevList];
              newList[existingIndex] = updatedMeta;
               // Re-sort maybe needed if sorting is purely client-side
               // newList.sort((a, b) => new Date(b.updated_at).getTime() - new Date(a.updated_at).getTime());
              return newList;
          } else if (isNewConversation) {
              // Add new metadata item (need title - fetch full or extract from active?)
              // Fetching full might be inefficient, extracting from activeConversationContent is better if available
               const newMeta: ConversationMetadata = {
                   id: realConversationId,
                   user_id: userId,
                   title: activeConversationContent?.title || messageToSend.substring(0,30) + "...", // Use title from active content or generate
                   created_at: now,
                   updated_at: now,
                   parent_conversation_id: null, // New root chat
                   branch_point_message_id: null
               };
              return [newMeta, ...prevList]; // Add to start (assuming sorted desc)
          }
          return prevList; // No change
      });

      // Ensure the newly created/updated conversation is active
      if (activeConversationId !== realConversationId) {
          setActiveConversationId(realConversationId);
      }


    } catch (err) {
      console.error("API Error:", err);
      setError(err instanceof Error ? err.message : String(err));
       // Consider adding error message to chat UI as well
       // Rollback optimistic update if error occurred after it
       if (activeConversationContent?.messages.at(-1)?.id === tempUserMessageId) {
          setActiveConversationContent(prev => prev ? { ...prev, messages: prev.messages.slice(0, -1) } : null);
      }
    } finally {
      setIsLoadingResponse(false);
    }
  };

  const handleBranch = async (messageId: string) => {
    if (!activeConversationId || !userId || isLoadingResponse || isLoadingContent) return;

    setIsLoadingResponse(true); // Use same loading state? Or a dedicated branching state?
    setError(null);

    try {
       const response = await fetch(`/api/conversations/${activeConversationId}/branch`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message_id: messageId, user_id: userId }) // Pass user_id for backend check
       });

       if (!response.ok) {
           const errorData = await response.json().catch(() => ({ detail: "Branching failed" }));
           throw new Error(`Branching error ${response.status}: ${errorData.detail || response.statusText}`);
       }

       const newBranchConversation: Conversation = await response.json();

       // --- Update State after successful branch ---

       // 1. Set the new branch as the active conversation content
       setActiveConversationContent(newBranchConversation);

       // 2. Set the new branch ID as the active ID
       setActiveConversationId(newBranchConversation.id);

       // 3. Add metadata for the new branch to the list
       setConversationMetadataList(prevList => {
           const newMeta: ConversationMetadata = {
               id: newBranchConversation.id,
               user_id: newBranchConversation.user_id,
               title: newBranchConversation.title,
               created_at: newBranchConversation.created_at,
               updated_at: newBranchConversation.updated_at,
               parent_conversation_id: newBranchConversation.parent_conversation_id,
               branch_point_message_id: newBranchConversation.branch_point_message_id
           };
            // Add to the beginning assuming descending sort
           return [newMeta, ...(prevList || [])];
       });

    } catch (err) {
         console.error("Branching Error:", err);
         setError(`Failed to create branch: ${err instanceof Error ? err.message : String(err)}`);
    } finally {
        setIsLoadingResponse(false);
    }
  };

  // Model/Provider Selection Handlers (update state)
  const handleProviderChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    const newProvider = e.target.value;
    setSelectedProvider(newProvider);
    // Automatically select the best/first model for the new provider
    const bestModel = findBestModelForProvider(models, newProvider);
    setSelectedModelId(bestModel || ""); // Set to empty if no models found
  };

  const handleModelChange = (e: React.ChangeEvent<HTMLSelectElement>) => {
    setSelectedModelId(e.target.value);
  };

  useEffect(() => {
    if (status === 'authenticated' && userId && !conversationMetadataList) {
        fetchMetadata();
    }
    // If user logs out, clear the state
    if (status === 'unauthenticated') {
         setConversationMetadataList(null);
         setActiveConversationContent(null);
         setActiveConversationId(null);
    }
  }, [status, userId, fetchMetadata, conversationMetadataList]);

  // --- Fetch full content when active ID changes ---
  useEffect(() => {
    if (activeConversationId && userId) {
         // Optional: Check if content for this ID is already loaded to avoid refetch
         // if (activeConversationContent?.id !== activeConversationId) {
            fetchFullConversation(activeConversationId);
         // }
    } else {
        // Clear content if no ID is active
        setActiveConversationContent(null);
    }
  }, [activeConversationId, userId, fetchFullConversation]);

  const getBranchChildren = (messageId: string): ConversationMetadata[] => {
    if (!conversationMetadataList || !activeConversationId) return [];
    return conversationMetadataList.filter(meta =>
        meta.parent_conversation_id === activeConversationId &&
        meta.branch_point_message_id === messageId
    );
  };

  return (
    // Use flex layout for sidebar + main content
    <div className="flex h-screen font-[family-name:var(--font-geist-sans)]">
        {/* Sidebar */}
        {status === 'authenticated' && (
             <ChatSidebar
                 metadataList={conversationMetadataList || []}
                 activeId={activeConversationId}
                 onSelect={handleSelectConversation}
                 onCreateNew={handleCreateNewChat}
                 isLoading={isLoadingMetadata}
             />
        )}
        {/* Add placeholder or message if not authenticated */}
         {status === 'loading' && <div className="w-64 pr-4 border-r border-gray-300 dark:border-gray-700 flex items-center justify-center"><p>Loading session...</p></div>}
         {status === 'unauthenticated' && (
             <div className="w-64 pr-4 border-r border-gray-300 dark:border-gray-700 flex flex-col p-4 items-center justify-center text-center">
                 <p className="text-sm mb-4">Sign in to view and save conversations.</p>
                 <Link href="/auth/signin" className="text-blue-500 underline">Sign In</Link>
             </div>
         )}


        {/* Main Chat Area */}
        <div className="flex-1 flex flex-col p-4 md:p-8 overflow-y-auto">
            <header className="mb-4 flex justify-between items-center">
                <Link href="/" className="text-xl md:text-2xl font-bold">ThreadFlow</Link>
                {/* Maybe add Sign Out button here? */}
            </header>

            <main className="flex-1 flex flex-col max-w-3xl mx-auto w-full">
                <h1 className="text-xl md:text-3xl font-bold mb-4 truncate" title={activeConversationContent?.title || "Chat"}>
                    {activeConversationContent?.title || (activeConversationId ? "Loading..." : "Select or Start a Chat")}
                </h1>

                {error && (
                  <div className="bg-red-100 border border-red-400 text-red-700 p-3 rounded mb-4 text-sm">
                    <p>Error: {error}</p>
                  </div>
                )}

                {/* Chat Messages Display */}
                <div className="bg-black/[.05] dark:bg-white/[.06] rounded-lg p-4 md:p-6 mb-6 flex-1 flex flex-col space-y-4 overflow-y-auto min-h-[200px]">
                     {isLoadingContent && <p className="text-gray-500 text-center">Loading conversation...</p>}
                     {!isLoadingContent && !activeConversationContent && status === 'authenticated' && <p className="text-gray-500 text-center">Select a conversation or start a new one.</p>}
                     {!isLoadingContent && status !== 'authenticated' && <p className="text-gray-500 text-center">Please sign in to chat.</p>}

                     {activeConversationContent?.messages.map((message) => {
                         const branchChildren = getBranchChildren(message.id);
                         const hasBranches = branchChildren.length > 0;
                         return (
                             <div
                                 key={message.id}
                                 className={`p-3 rounded-lg relative max-w-[80%] break-words ${
                                     message.role === "user"
                                         ? "bg-blue-100 dark:bg-blue-900 self-end"
                                         : "bg-gray-100 dark:bg-gray-700 self-start"
                                 }`}
                             >
                                 <p className="whitespace-pre-wrap">{message.content}</p>
                                 {/* Branch Button & Indicator */}
                                 <div className="absolute top-0 -right-2 transform translate-x-full flex flex-col items-center opacity-50 hover:opacity-100 transition-opacity">
                                     <button
                                         onClick={() => handleBranch(message.id)}
                                         className="p-1 bg-gray-200 dark:bg-gray-600 rounded-full text-xs leading-none"
                                         title="Branch from this message"
                                         disabled={isLoadingResponse || isLoadingContent || !activeConversationId}
                                     >
                                         {/* Simple Branch Icon (e.g., Fork) */}
                                          <svg xmlns="http://www.w3.org/2000/svg" className="h-3 w-3" fill="none" viewBox="0 0 24 24" stroke="currentColor" strokeWidth={2}>
                                              <path strokeLinecap="round" strokeLinejoin="round" d="M15 15l-2 5L9 9l11 4-5 2zm0 0l5 5M7.188 2.239l.777 2.897M5.136 7.965l-2.898-.777M13.95 4.05l-2.122 2.122m-5.657 5.656l-2.12 2.122" />
                                          </svg>
                                     </button>
                                      {hasBranches && (
                                         <span className="mt-1 text-[10px] text-gray-500 dark:text-gray-400" title={`Branched ${branchChildren.length} time(s)`}>
                                             {/* Maybe list children titles on hover? */}
                                             ({branchChildren.length})
                                         </span>
                                     )}
                                 </div>
                             </div>
                         );
                     })}

                    {isLoadingResponse && (
                      <div className="text-gray-500 italic self-start">
                        Getting response...
                      </div>
                    )}
                </div>

                {/* Model Selection (reuse existing logic) */}
                <div className="mb-4 flex flex-col sm:flex-row gap-4">
                   <div className="flex-1">
                       <label htmlFor="provider" className="block text-sm font-medium mb-1">Provider</label>
                       <select
                         id="provider"
                         className="w-full p-2 border border-gray-300 dark:border-gray-700 rounded-lg bg-white dark:bg-gray-800 disabled:opacity-50"
                         value={selectedProvider}
                         onChange={handleProviderChange} // Need to implement handler
                         disabled={isLoadingModels || isLoadingResponse || !models || !activeConversationId}
                       >
                         {isLoadingModels ? ( <option>Loading...</option> ) :
                           !models ? (<option>Error loading</option>) :
                           (Object.keys(models).map(provider => (
                             <option
                               key={provider}
                               value={provider}
                               disabled={!isProviderAvailable(models, provider)}
                             >
                               {provider.charAt(0).toUpperCase() + provider.slice(1)} {!isProviderAvailable(models, provider) && "(API key required)"}
                             </option>
                           ))
                         )}
                       </select>
                     </div>
                     <div className="flex-1">
                       <label htmlFor="model" className="block text-sm font-medium mb-1">Model</label>
                       <select
                         id="model"
                         className="w-full p-2 border border-gray-300 dark:border-gray-700 rounded-lg bg-white dark:bg-gray-800 disabled:opacity-50"
                         value={selectedModelId}
                         onChange={handleModelChange} // Need to implement handler
                         disabled={isLoadingModels || isLoadingResponse || !models || !selectedProvider || !models[selectedProvider]?.models.length || !activeConversationId}
                       >
                           {isLoadingModels ? (<option>Loading...</option>) :
                            !models || !models[selectedProvider]?.models.length ? (<option>Select Provider</option>) :
                           (models[selectedProvider]?.models.map((model) => (
                             <option key={model.id} value={model.id}>
                               {model.name}
                             </option>
                           ))
                         )}
                       </select>
                   </div>
                </div>
                {selectedProvider && selectedModelId && models && (
                    <div className="mb-4 text-sm text-gray-500 dark:text-gray-400">
                        <p>{getModelDescription(models, selectedProvider, selectedModelId)}</p>
                    </div>
                )}


                {/* Input Form */}
                <form onSubmit={handleSubmit} className="flex flex-col gap-4">
                     <textarea
                         className="w-full p-4 border border-gray-300 dark:border-gray-700 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 bg-white dark:bg-gray-800 min-h-[100px] resize-none disabled:opacity-50"
                         placeholder="Type your message here..."
                         value={userInput}
                         onChange={(e) => setUserInput(e.target.value)}
                         disabled={isLoadingResponse || isLoadingContent || !activeConversationId || !selectedModelId}
                     />
                     <button
                         type="submit"
                         disabled={isLoadingResponse || !userInput.trim() || !activeConversationId || !selectedModelId || isLoadingContent}
                         className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] text-sm sm:text-base h-10 md:h-12 px-5 disabled:opacity-50 disabled:cursor-not-allowed self-end"
                     >
                        {isLoadingResponse ? "Sending..." : "Send Message"}
                     </button>
                </form>
            </main>
        </div>
    </div>
  );
}

--- File: frontend/src/app/globals.css ---

@import "tailwindcss";

@theme {
  --font-sans: var(--font-geist-sans);
  --font-mono: var(--font-geist-mono);
}

:root {
  --background: #ffffff;
  --foreground: #171717;
}

@media (prefers-color-scheme: dark) {
  :root {
    --background: #0a0a0a;
    --foreground: #ededed;
  }
}

body {
  color: var(--foreground);
  background: var(--background);
  font-family: Arial, Helvetica, sans-serif;
}


--- File: frontend/src/app/layout.tsx ---

// src/app/layout.tsx
import "./globals.css";
import { ClientProviders } from "./ClientProviders";

export default function RootLayout({
  children,
}: {
  children: React.ReactNode;
}) {
  return (
    <html lang="en">
      <body>
        <ClientProviders>
          {children}
        </ClientProviders>
      </body>
    </html>
  );
}


--- File: frontend/src/app/page.tsx ---

"use client";

import Link from "next/link";
import { useState, useEffect } from "react";
import { signIn, signOut, useSession } from "next-auth/react";

export default function Home() {
  const [apiStatus, setApiStatus] = useState<string>("Checking...");
  const [statusClass, setStatusClass] = useState<string>("");
  const { data: session, status } = useSession();

  useEffect(() => {
    fetch('/api/health')
      .then(response => response.json())
      .then(data => {
        setApiStatus(data.status || "Online");
        setStatusClass("text-green-500 font-bold");
      })
      .catch(() => {
        setApiStatus("Offline");
        setStatusClass("text-red-500 font-bold");
      });
  }, []);

  return (
    <div className="grid grid-rows-[20px_1fr_20px] items-center justify-items-center min-h-screen p-8 pb-20 gap-16 sm:p-20 font-[family-name:var(--font-geist-sans)]">
      <main className="flex flex-col gap-8 row-start-2 items-center sm:items-start">
        <h1 className="text-4xl font-bold">ThreadFlow</h1>
        <p className="text-xl mb-6">A branching chat interface for LLMs</p>
        
        <div className="p-4 bg-black/[.05] dark:bg-white/[.06] rounded-lg mb-6">
          <p>
            API Status: <span className={statusClass}>{apiStatus}</span>
          </p>
        </div>

        {/* Google Authentication Section */}
        <div className="flex gap-4 items-center">
          {status === "loading" ? (
            <p>Loading...</p>
          ) : session ? (
            <div className="flex items-center gap-2">
              <p className="text-sm">Signed in as {session.user?.email}</p>
              <button
                onClick={() => signOut()}
                className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-red-500 text-white gap-2 hover:bg-red-600 text-sm h-10 px-4"
              >
                Sign out
              </button>
            </div>
          ) : (
            <button
              onClick={(e) => {e.preventDefault();signIn("google", { callbackUrl: "/" })}}
              className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-blue-500 text-white gap-2 hover:bg-blue-600 text-sm h-10 px-4"
            >
              Sign in with Google
            </button>
          )}
        </div>

        <div className="flex gap-4 items-center flex-col sm:flex-row">
          <Link
            className="rounded-full border border-solid border-transparent transition-colors flex items-center justify-center bg-foreground text-background gap-2 hover:bg-[#383838] dark:hover:bg-[#ccc] text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5"
            href="/chat"
          >
            Start a Conversation
          </Link>
          <Link
            className="rounded-full border border-solid border-black/[.08] dark:border-white/[.145] transition-colors flex items-center justify-center hover:bg-[#f2f2f2] dark:hover:bg-[#1a1a1a] hover:border-transparent text-sm sm:text-base h-10 sm:h-12 px-4 sm:px-5 sm:min-w-44"
            href="/about"
          >
            About ThreadFlow
          </Link>
        </div>
      </main>
      <footer className="row-start-3 flex gap-6 flex-wrap items-center justify-center">
        <p className="text-sm">Team 29 Project</p>
      </footer>
    </div>
  );
}


--- File: frontend/src/types/models.ts ---

export type ModelConfig = {
  id: string;
  name: string;
  description: string;
};

export type ProviderConfig = {
  available: boolean;
  models: ModelConfig[];
};

export type ModelsResponse = {
  [provider: string]: ProviderConfig;
};

export type MessageItem = {
  id: string;
  role: "user" | "assistant";
  content: string;
  timestamp: string; // ISO Date string from backend
};

export type Conversation = {
  id: string;
  user_id: string;
  title: string;
  messages: MessageItem[];
  created_at: string; // ISO Date string
  updated_at: string; // ISO Date string
  parent_conversation_id: string | null;
  branch_point_message_id: string | null;
};

// Metadata for a conversation (excluding messages), used for lists/trees
export type ConversationMetadata = Omit<Conversation, 'messages'>;

// Response type from the modified POST /chat endpoint
export type ChatApiResponse = {
    response: string;
    conversation_id: string;
    user_message_id: string;
    assistant_message_id: string;
};

--- File: frontend/src/types/next-auth.d.ts ---

import "next-auth";
import { JWT } from "next-auth/jwt";

declare module "next-auth" {
  interface Session {
    accessToken?: string;
    user: {
      id?: string;
      name?: string;
      email?: string;
      image?: string;
    }
  }
}

declare module "next-auth/jwt" {
  interface JWT {
    accessToken?: string;
  }
}

--- File: frontend/src/utils/modelUtils.ts ---

import { ModelsResponse } from '../types/models';

/**
 * Finds the best available model for a given provider
 * @param models The available models response
 * @param provider The provider to find models for
 * @returns The ID of the best model, or undefined if no models available
 */
export function findBestModelForProvider(
  models: ModelsResponse | null,
  provider: string
): string | undefined {
  if (!models || !models[provider]?.models.length) {
    return undefined;
  }
  
  // Special handling for different providers
  if (provider === 'anthropic') {
    // Prefer Claude 3.7 Sonnet
    const claude37 = models[provider].models.find(m => m.id === 'claude-3-7-sonnet-20250219');
    if (claude37) return claude37.id;
  }
  else if (provider === 'google') {
    // Prefer Gemini 2.5 Pro
    const gemini25 = models[provider].models.find(m => m.id === 'gemini-2.5-pro-exp-03-25');
    if (gemini25) return gemini25.id;
  }
  else if (provider === 'openai') {
    // Prefer GPT-4o
    const gpt4o = models[provider].models.find(m => m.id === 'gpt-4o');
    if (gpt4o) return gpt4o.id;
  }
  
  // Default to first model
  return models[provider].models[0].id;
}

/**
 * Gets the description for a specific model
 * @param models The available models response
 * @param provider The provider of the model
 * @param modelId The model ID
 * @returns The model description or empty string if not found
 */
export function getModelDescription(
  models: ModelsResponse | null,
  provider: string,
  modelId: string
): string {
  if (!models || !models[provider]) return '';
  
  const model = models[provider].models.find(m => m.id === modelId);
  return model?.description || '';
}

/**
 * Checks if the provider has any available models
 * @param models The available models response
 * @param provider The provider to check
 * @returns True if the provider has available models
 */
export function isProviderAvailable(
  models: ModelsResponse | null,
  provider: string
): boolean {
  return Boolean(models?.[provider]?.available && models[provider].models.length > 0);
}

--- File: frontend/tsconfig.json ---

{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts", "src/app/api/auth/[...nextauth].ts.bk"],
  "exclude": ["node_modules"]
}
